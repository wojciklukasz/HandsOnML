{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatper 3 exercise 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the KNeighborsClassifier works quite well for this task; you just need to find good hyperparameter values (try a grid search on the weights and n_neighbors hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import shift\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", as_frame=False, parser=\"auto\")\n",
    "\n",
    "data_train, data_test = mnist.data[:60000], mnist.data[60000:]\n",
    "labels_train, labels_test = mnist.target[:60000], mnist.target[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:   43.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9676 , 0.9671 , 0.96755])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights=\"uniform\")\n",
    "cross_val_score(\n",
    "    knn, data_train, labels_train, cv=3, scoring=\"accuracy\", n_jobs=4, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically there already :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...n_neighbors=3, weights=distance;, score=0.970 total time=  36.2s\n",
      "[CV 1/3] END ....n_neighbors=3, weights=uniform;, score=0.969 total time=  37.5s\n",
      "[CV 3/3] END ....n_neighbors=3, weights=uniform;, score=0.968 total time=  39.7s\n",
      "[CV 2/3] END ....n_neighbors=3, weights=uniform;, score=0.968 total time=  39.7s\n",
      "[CV 2/3] END ...n_neighbors=3, weights=distance;, score=0.969 total time=  34.6s\n",
      "[CV 3/3] END ...n_neighbors=3, weights=distance;, score=0.969 total time=  33.7s\n",
      "[CV 1/3] END ....n_neighbors=4, weights=uniform;, score=0.966 total time=  37.3s\n",
      "[CV 2/3] END ....n_neighbors=4, weights=uniform;, score=0.966 total time=  39.0s\n",
      "[CV 1/3] END ...n_neighbors=4, weights=distance;, score=0.971 total time=  36.3s\n",
      "[CV 3/3] END ....n_neighbors=4, weights=uniform;, score=0.967 total time=  37.8s\n",
      "[CV 2/3] END ...n_neighbors=4, weights=distance;, score=0.970 total time=  35.0s\n",
      "[CV 3/3] END ...n_neighbors=4, weights=distance;, score=0.970 total time=  35.1s\n",
      "[CV 1/3] END ....n_neighbors=5, weights=uniform;, score=0.968 total time=  34.8s\n",
      "[CV 2/3] END ....n_neighbors=5, weights=uniform;, score=0.967 total time=  34.6s\n",
      "[CV 3/3] END ....n_neighbors=5, weights=uniform;, score=0.968 total time=  34.3s\n",
      "[CV 1/3] END ...n_neighbors=5, weights=distance;, score=0.969 total time=  33.5s\n",
      "[CV 2/3] END ...n_neighbors=5, weights=distance;, score=0.968 total time=  35.2s\n",
      "[CV 3/3] END ...n_neighbors=5, weights=distance;, score=0.969 total time=  34.9s\n",
      "[CV 1/3] END ....n_neighbors=6, weights=uniform;, score=0.965 total time=  33.2s\n",
      "[CV 2/3] END ....n_neighbors=6, weights=uniform;, score=0.965 total time=  35.3s\n",
      "[CV 1/3] END ...n_neighbors=6, weights=distance;, score=0.970 total time=  36.4s\n",
      "[CV 2/3] END ...n_neighbors=6, weights=distance;, score=0.969 total time=  35.1s\n",
      "[CV 3/3] END ....n_neighbors=6, weights=uniform;, score=0.966 total time=  38.0s\n",
      "[CV 3/3] END ...n_neighbors=6, weights=distance;, score=0.970 total time=  36.9s\n",
      "[CV 1/3] END ....n_neighbors=7, weights=uniform;, score=0.965 total time=  35.9s\n",
      "[CV 2/3] END ....n_neighbors=7, weights=uniform;, score=0.965 total time=  36.3s\n",
      "[CV 1/3] END ...n_neighbors=7, weights=distance;, score=0.967 total time=  31.7s\n",
      "[CV 3/3] END ....n_neighbors=7, weights=uniform;, score=0.966 total time=  35.7s\n",
      "[CV 2/3] END ...n_neighbors=7, weights=distance;, score=0.966 total time=  25.2s\n",
      "[CV 3/3] END ...n_neighbors=7, weights=distance;, score=0.967 total time=  25.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=4,\n",
       "             param_grid={&#x27;n_neighbors&#x27;: range(3, 8),\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=4,\n",
       "             param_grid={&#x27;n_neighbors&#x27;: range(3, 8),\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(), n_jobs=4,\n",
       "             param_grid={'n_neighbors': range(3, 8),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_neighbors\": range(3, 8),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "}\n",
    "\n",
    "classifier = GridSearchCV(\n",
    "    estimator=knn, param_grid=params, scoring=\"accuracy\", n_jobs=4, cv=3, verbose=3\n",
    ")\n",
    "classifier.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.best_params_  # {'n_neighbors': 4, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.973     , 0.97225   , 0.96991667, 0.97091667, 0.972     ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = KNeighborsClassifier(n_neighbors=4, weights=\"distance\")\n",
    "cross_val_score(\n",
    "    best_knn, data_train, labels_train, scoring=\"accuracy\", n_jobs=4, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All splits above or almost at 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn.fit(data_train, labels_train)\n",
    "accuracy_score(best_knn.predict(data_test), labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel.⁠ Then, for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now! This technique of artificially growing the training set is called data augmentation or training set expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(image, direction):\n",
    "    if direction == \"left\":\n",
    "        return shift(image.reshape(28, 28), (0, -1), cval=0).flatten()\n",
    "    elif direction == \"right\":\n",
    "        return shift(image.reshape(28, 28), (0, 1), cval=0).flatten()\n",
    "    elif direction == \"up\":\n",
    "        return shift(image.reshape(28, 28), (-1, 0), cval=0).flatten()\n",
    "    elif direction == \"down\":\n",
    "        return shift(image.reshape(28, 28), (1, 0), cval=0).flatten()\n",
    "    else:\n",
    "        return \"Invalid direction!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_images = []\n",
    "shifted_labels = []\n",
    "\n",
    "for image, label in zip(data_train, labels_train):\n",
    "    for direction in [\"left\", \"right\", \"up\", \"down\"]:\n",
    "        shifted_images.append(shift_image(image, direction))\n",
    "        shifted_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_images = np.array(shifted_images)\n",
    "shifted_labels = np.array(shifted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_augmented = np.concatenate((data_train, shifted_images))\n",
    "labels_train_augmented = np.concatenate((labels_train, shifted_labels))\n",
    "data_train_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = KNeighborsClassifier(n_neighbors=4, weights=\"distance\")\n",
    "best_knn.fit(data_train_augmented, labels_train_augmented)\n",
    "accuracy_score(best_knn.predict(data_test), labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
